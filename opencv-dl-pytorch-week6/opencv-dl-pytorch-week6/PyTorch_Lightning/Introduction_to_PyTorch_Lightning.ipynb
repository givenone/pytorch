{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Introduction to PyTorch Lightning</font>\n",
    "\n",
    "---\n",
    "\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2020/05/PTL.png'>\n",
    "\n",
    "<center><h4>Source: https://www.learnopencv.com/getting-started-with-pytorch-lightning/</h4></center>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**What is PyTorch Lightning, and why do we need it?**\n",
    "\n",
    "PyTorch Lightning is a lightweight PyTorch wrapper that provides simple templates for organizing PyTorch code. Once we organize our code with the lightning module, it automates most of the training. Let's list a few things that can be automated by PyTorch Lightning:\n",
    "\n",
    "\n",
    "- **Training loop:** Using PyTorch, we iterate through training data in batches and do some fixed operations with a batch of data in training. However, by using PyTorch Lighting, we can get rid of code for data iteration, and writing code for the fixed operation will be sufficient. \n",
    "\n",
    "\n",
    "- **Validation and test loop:** Like the training loop, we can also get rid of the validation and test loop that is required for data iteration. Writing fix operations will be sufficient here as well. \n",
    "\n",
    "\n",
    "- **GPU/CPU training:** In the case of PyTorch, if we want to use GPU for training, it is mandatory to transfer data and models to GPU. Failing to do it leads to error or training on the CPU. However, if we use PyTorch Lightning, we get rid of transferring data from one device to another device. We only need to choose if we want to use GPU or not, and transfer operation will be taken care of by PyTorch Lightning. Further, if we want to use multiple GPUs or even multiple nodes (machine), we need not worry about code changes; this will be taken care of by Lightning.\n",
    "\n",
    "\n",
    "\n",
    "- **Training with different precision:** A model can be trained with different precision, for example, 8-bit, 16-bit, 32-bit, etc. Lower the model precision higher the inference speed will be. If we are using PyTorch Lighting, we need not write any code for different precision. By enabling corresponding flags, we can train with different precession. \n",
    "\n",
    "\n",
    "- **Evaluation metrics:** It supports different evaluation metrics such as accuracy, precision, recall, f1-score, etc.\n",
    "\n",
    "\n",
    "- **Logging:** Tensorboard (also supports other logging, e.g., Comet, Neptune, etc.) logging becomes very handy with it.\n",
    "\n",
    "\n",
    "- **Progress bar:** We get a progress bar without writing any code for it.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Looking at the above benefits, it seems that code will cleaner, so less prone to error. To get these benefits, do we need to compromise with the power of PyTorch?** \n",
    "\n",
    "No, PyTorch Lightning solves repeated steps and the engineering part of the problem. It does not compromise with model building, training steps, etc.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**We will cover the following in this section:**\n",
    "\n",
    "- **PyTorch to PyTorch Lightning:** We will take a PyTorch notebook and convert it to a PyTorch Lightning notebook.\n",
    "\n",
    "\n",
    "- **Inference on production:** There are a lot of libraries for machine learning and deep learning, and different people and teams use the library of their choice. This creates the need to share models across teams in some common format. ONNX is one of the formats.  We will see how we can transform `.ckpt`  into `.onnx`. And we will also see how to do inference using the .onnx formated model.\n",
    "\n",
    "\n",
    "\n",
    "- **Transfer learning:** We will see how to use transfer learning in PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Installation</font>\n",
    "\n",
    "Installation of PyTorch Lighting is very simple; it can be installed using pip and conda. \n",
    "\n",
    "\n",
    "## <font style=\"color:green\">pip installation</font>\n",
    "\n",
    "```\n",
    "pip install pytorch-lightning\n",
    "```\n",
    "\n",
    "\n",
    "## <font style=\"color:green\">conda installation</font>\n",
    "\n",
    "```\n",
    "conda install pytorch-lightning -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Reference</font>\n",
    "\n",
    "1. https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09\n",
    "1. https://www.learnopencv.com/getting-started-with-pytorch-lightning/\n",
    "1. https://github.com/PyTorchLightning/pytorch-lightning\n",
    "1. https://pytorch-lightning.readthedocs.io/en/latest/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
